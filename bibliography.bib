@book{deisenroth2013survey,
  title={A survey on policy search for robotics},
  author={Deisenroth, Marc Peter and Neumann, Gerhard and Peters, Jan},
  year={2013},
  publisher={now publishers}
}

@article{RobinRuede2021,
    title = {Bayesian and Attentive Aggregation for Multi-Agent Deep Reinforcement Learning},
    author = {Ruede, Robin and Neumann, Gerhard and Asfour, Tamim and Huettenrauch, Maximilian},
    abstract = {Multi-agent reinforcement learning (MARL) is an emerging field in reinforcement learning with real world applications such as unmanned aerial vehicles, search-and-rescue, and warehouse organization. There are many different approaches for applying the methods used for single-agent reinforcement learning to MARL. In this work, we survey different learning methods and environment properties and then focus on a problem that persists through most variants of MARL: How should one agent use the information gathered from a large and varying number of observations of the world in order to make decisions? We focus on three different methods for aggregating observations and compare them regarding their training performance and sample eï¬€iciency. We introduce a policy architecture for aggregation based on Bayesian conditioning and compare it to mean aggregation and attentive aggregation used in related work. We show the performance of the different methods on a set of cooperative tasks that can scale to a large number of agents, including tasks that have other objects in the world that need to be observed by the agents in order to solve the task. We optimize the hyperparameters to be able to show which parameters lead to the best results for each of the methods. In addition, we compare different variants of Bayesian aggregation and compare the recently introduced Trust Region Layers learning method to the commonly used Proximal Policy Optimization.},
    year = {2021},
    url = {https://phiresky.github.io/masters-thesis/manuscript.pdf},
    keywords = {Multi-Agent Reinforcement Learning},
    journal={Autonomous Learning Robotics (ALR)}
}

@inproceedings{otto2021differentiable,
title={Differentiable Trust Region Layers for Deep Reinforcement Learning},
author={Fabian Otto and Philipp Becker and Vien Anh Ngo and Hanna Carolin Maria Ziesche and Gerhard Neumann},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=qYZD-AO1Vn}
}

@article{SchulmanWDRK17,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.06347},
  eprinttype = {arXiv},
  eprint    = {1707.06347},
  timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}