% !TeX spellcheck = en_US
% !TeX encoding = UTF-8
% !TeX root = ../thesis.tex

\chapter{Related Work}
\label{ch:Related Work}

This chapter will highlight some related work in the field of Multi-Agent Reinforcement Learning (MARL) and Graph Neural Networks (GNN).



\section{Multi Agent Reinforcement Learning}
\textbf{Homogeneous and Heterogeneous Agents:}\\
Our thesis used homogeneous agents, where each of them has the same capabilities. They can sense the same information and do the same actions as any other agent. In the heterogeneous case, the agents can differ in a variety of ways. They are better at certain actions, or are not able to do some of them, having better observation range or different kind of sensors, or their entire movement dynamics can be different. In \citet{ISHIWAKA2003245} the authors defined an approach to the Pursuit problem \Cref{sec:Single Evader Pursuit}. Their evader used a deterministic set of rules for movement. Each of their agents used their own Q-Learning network to make its own decision. If an agent can see the evader, it will directly go to it, otherwise it can predict the position using communication between the evaders. Each agent started to create its own prediction which led to heterogeneous behaviour. Some agents chased the evader and others tried to ambush it.\par

\textbf{Different Topologies:} \\
How the agents are organized in terms of communication and coordination is called the topology. They can work together in a hierarchical system. In \citet{Intrusion2008} the authors adapt an MARL approach for detecting network intrusions in computer networks. They apply RL to multiple agents, each responsible for several systems that report heterogeneous sensor data of the network, called a cell. Because of bandwidth restriction and for better modelling real life computer networks, they opted to use a hierarchical approach. One cell itself can communicate with an agent higher in the hierarchy. Each of the Cells and highest hierarchy learn to monitor the system and to look for abnormal signals. One other benefit they outlined is that this structure would be easy to adapt to different network architectures. \par

In addition to classic hierarchical structures, agents can be organized in fractal structures. The holon was originally proposed as a model for the social behaviour of biological species back in 1968 \citep{koestler1968ghost}. It describes a self-similar structure of connected individuals. In MARL, it has been used to describe a flexible structure of agents. In the holon hierarchy we describe the holons on the same level as sub-holons and the holon of the higher level as super-holons. In \citet{Holonic2013} the authors use this structure to solve the traffic signal control problem of larger cities, with two levels of holons. The holonic structure allows for communication between sub-holons of a level (intra-level), similar to other MARL Approaches and communication to the super-holon of a level (inter-level). Information about observation, actions and rewards are abstracted for the higher super-holon. Through subdividing the problem, they achieved less average delay time and higher flow rate.

\textbf{Cooperation: Team, Adversarial, Cooperative} \\
How the agents interact with each other to solve the task at hand can also be different. Tasks can be of adversarial nature. Each of the agents is competing against each other. The authors of \citet{MAgent2018} defined a platform for research on MARL called MAgent, which includes multiple tasks. One of these tasks is called gather. Here multiple agents have to compete for a limited number of resources. They can get a reward directly by eating the food. But they are also able to eliminate other agents and by doing so can monopolize on more food. Their training showed that the agents rushed into a central amount of food to gather as much as possible. Only when two agents were close enough, they tried to eliminate each other.\par

But agents are not limited to adversarial behaviour, they are able to learn to work together in a cooperative environment. Foraging is a cooperative task used in \citet{Foraging2013}. It is based on animal behaviour that can be found in ants, for example. The environment is filled with food and the goal is to collect it. To do so, the agents have a single central drop off point. They are required to search the environment, which is filled with obstacles. Therefore, navigation is an extra part of the problem. The level of cooperation can be increased by using communication to inform other agents of resource locations and to coordinate searching efforts. \par

In a team-based scenario, the agents are segmented into multiple teams that each must compete with each other. In \citet{Teams2019} the OpenAI team used a team-based task of hide-and-seek. They only used the line-of-sight for the seekers and hiders as the goal and reward for both teams. The reward was given out for the whole team. They have shown that the agents developed multiple stages of strategy and counter-strategy between both teams.




\section{Graph Neural Networks}
Graph Neural Networks (GNN) have been used for different problems and in different structures, but the research is still in its early stages. Graph Network-based Simulators (GNS) is a structure proposed in \citet{GNS2020}. Their goal was to create a structure that was able to learn physical interactions between particles, for liquids, solids and deformable materials. Graphs are used as representations for particles with message-passing utilized to express the physical dynamics. Edge represented the interaction of the particles in a radius. They encoded the physical state into a latent graph representation which then went through multiple GNN hops sequentially. The result of these were decoded back into a physical state. Their model was able to ablate from predictions of a single physics-timestep to different starting conditions, more timesteps and more particles in evaluations. \par

Graph Convolutional Networks (GCNs) were introduced for node-wise classification using graphs \citep{SGCN2019}. Multiple graph layers are used that can be learned by a neural network. At the end of the stack, the output is used by a classical linear classifier. Each of the layers has two steps. First, the features of the graph are propagated in a given layer using convolutional constants and the neighborhood as discussed for convolutional GNNs in \Cref{ch:Preliminaries}. Secondly the features are transformed for the next layer, similar to a Multi-Layer Perceptron (MLP). The model outperformed several other recent methods for classification significantly. \par

An extension to the GCNs is the Graph Attention Network (GAT), which uses the attentional flavour. The convolutional weights in GCN directly depend on the graph structure, which makes GCNs not as flexible. Instead \citet{GAT2017} uses an attention function to improve upon convolutions. The attention is itself a neural network and therefore learnable. As it only relies on nodes, it is essentially not restricted by the graph structure. In practice though, the combination of the attentional data is used for aggregating of neighbourhood features. Their approach was computationally efficient and does not require, that the entire graph structure is known upfront, which addresses a scalability issue. \par

\citet{G2ANet2020} features an application for GNN in MARL called G2ANet. They used two different layers of attentional GNN. Its output is then used for different MARL-Learning techniques. The first layer uses a hard attention function and takes a fully connected graph as input. It has only a binary output and is used to describe if there is a meaningful interaction between two agents. The second layer is a classical soft attention with a value range that defines how important a given edge is to the agents. This way they are able to create a graph structure that itself is learnable. They concluded that this approach was performing better than a lot of the state-of-the-art algorithms they compared it against.\par

