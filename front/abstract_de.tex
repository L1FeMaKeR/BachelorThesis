% !TeX spellcheck = de_DE
% !TeX encoding = UTF-8
% !TeX root = ../thesis.tex

\chapter*{Zusammenfassung}
\addcontentsline{toc}{chapter}{Zusammenfassung}
% 224-234 words

Das stehts wachsende Forschungsgebiet des Multi-Agent Reinforcement Learning (MARL) betrachtet Echtweltprobleme, in welchen mehrere Aktoren, genannt Agenten, entweder in kooperativer, kompetitiver oder in einer gemischten Art und Weise miteinander arbeiten müssen. Dies findet Anwendung bei der Beschreibung des Verhaltens von Ameisen, Bienen oder Vögeln. Ebenso findet dieser Ansatz für Such- und Rettungseinsätze, sowie der Modellierung von Netzwerksystemen Verwendung. Hierfür müssen die Agenten etwaige große Mengen an Beobachtungen über ihre Umwelt verarbeiten und lernen, um in der Lage zu sein die gestellte Aufgaben zu lösen. Somit ist eine effiziente Datenstruktur für die Observationen der Agenten unumgänglich, um große Mengen von Agenten lernen lassen zu können. 
Die Lernprozesse Graph Neural Networks (GNN) wurde entworfen, um als Graph konstrurierten Daten effektiv zu lernen. Jene eignen sich gut, um die Kommunikation zwischen den Agenten zu repräsentieren. In dieser Arbeit möchten wir die Auswirkung und den Nutzen von GNNs auf das Lernen von MARL Problemen untersuchen. Der Fokus liegt hierbei auf dem Effekt mehrerer Durchläufe von GNN auf die Informationsübertragung in Umgebungen mit sehr geringer partieller Sichtbarkeit.\par

In dieser Arbeit stellen wir eine Trainingsarchitektur vor, welche den Proximal Policy Optimization (PPO) Algorithmus verwendet. Zusätzlich besitzt sie ein GNN, welcher problemlos auf beliebig viele Durchläufe skalieren kann. Dieser Ansatz basiert auf der bereits veröffentlichten Arbeit für eine Multi-Agent Deep Reinforcement Learning Architektur, welche man in \citet{RobinRuede2021} findet. Zudem wurde die Architektur um die Fähigkeit erweitert, mit heterogenen Graphen arbeiten zu können. Jene wird nämlich für unser Observationsmodell in komplexeren Aufgaben benötigt. Anschließend wird in mehreren Multi-Agent Aufgaben der Nutzen von mehreren GNN Durchläufen beurteilt.\par

Unsere Ergebnisse zeigen, dass unter verschiedenen Restriktionen mehrere GNN Durchläufe das Ergebnis positiv beeinflussen können. Zu diesen Restriktionen zählen kleine latent Dimensionen, geringe Observations Radien und geringer Observationsinformation. Somit können MARL Probleme von mehreren GNN Durchläufen profitieren.